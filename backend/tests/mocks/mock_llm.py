"""
í…ŒìŠ¤íŠ¸ìš© Mock LLM
ì‹¤ì œ LLM ì—†ì´ë„ ê°œë°œ ë° í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
"""
import json
import time
import random
from typing import List, Dict, Any, Optional
from dataclasses import dataclass


@dataclass
class MockMessage:
    content: str
    role: str = "assistant"


@dataclass
class MockChatResponse:
    content: str

    @property
    def message(self):
        return MockMessage(content=self.content)


class MockChatLLM:
    """Mock Chat LLM - ì‚¬ë‚´ Chat LLM ëŒ€ì²´"""

    def __init__(self, model: str = "mock-gpt-4", temperature: float = 0.1):
        self.model = model
        self.temperature = temperature

    def invoke(self, prompt: str) -> MockChatResponse:
        """í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µ ìƒì„±"""
        time.sleep(0.5)  # ì‹¤ì œ API í˜¸ì¶œì²˜ëŸ¼ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜

        # Query Classification ì‘ë‹µ
        if "ë¶„ë¥˜í•˜ì„¸ìš”" in prompt or "classify" in prompt.lower():
            return self._classify_query(prompt)

        # ì¼ë°˜ ë‹µë³€ ìƒì„±
        if "ë¶€í’ˆ" in prompt or "ì¬ê³ " in prompt:
            return self._generate_parts_response(prompt)

        if "í‘œ" in prompt or "ê·¸ë˜í”„" in prompt:
            return self._generate_table_response(prompt)

        return MockChatResponse(
            content="Mock LLM ì‘ë‹µì…ë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‚¬ë‚´ LLMì´ ë‹µë³€í•©ë‹ˆë‹¤."
        )

    def _classify_query(self, prompt: str) -> MockChatResponse:
        """ì¿¼ë¦¬ ë¶„ë¥˜ Mock ì‘ë‹µ"""
        classification = {
            "intent": "part_search",
            "data_sources": ["mongodb", "vectordb"],
            "entities": {
                "part_numbers": ["ABC-12345"],
                "part_names": ["ë°˜ë„ì²´ ì¹© A"],
                "date_ranges": [],
                "metrics": ["ì¬ê³ "]
            },
            "requires_calculation": False,
            "response_format": "mixed"
        }
        return MockChatResponse(content=json.dumps(classification, ensure_ascii=False))

    def _generate_parts_response(self, prompt: str) -> MockChatResponse:
        """ë¶€í’ˆ ê´€ë ¨ ì‘ë‹µ ìƒì„±"""
        response = """
ë¶€í’ˆ ABC-12345 (ë°˜ë„ì²´ ì¹© A)ì˜ í˜„ì¬ ì¬ê³  ì •ë³´ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤:

**ì¬ê³  í˜„í™©**
- ì´ ì¬ê³ : 1,000ê°œ
- ê°€ìš© ì¬ê³ : 850ê°œ
- ì˜ˆì•½: 150ê°œ
- ìƒíƒœ: ì •ìƒ

**ìµœê·¼ ì¶œê³  ì´ë ¥ (í‘œ)**

| ë‚ ì§œ | ìˆ˜ëŸ‰ | ëª©ì ì§€ | ë‹´ë‹¹ì |
|------|------|---------|--------|
| 2024-01-15 | 100ê°œ | ë¼ì¸ 1 | ê¹€ì² ìˆ˜ |
| 2024-01-10 | 50ê°œ | ë¼ì¸ 2 | ì´ì˜í¬ |
| 2024-01-05 | 75ê°œ | ë¼ì¸ 1 | ë°•ë¯¼ìˆ˜ |

**ì¥ì°© í˜„í™©**
- ì¥ë¹„ EQ-001: í™œì„± (ê°€ë™ë¥  95%)
- ì¥ë¹„ EQ-002: í™œì„± (ê°€ë™ë¥  88%)

**ì›”ë³„ ì¬ê³  ì¶”ì´ (ê·¸ë˜í”„)**
```json
{
  "type": "line",
  "title": "ìµœê·¼ 6ê°œì›” ì¬ê³  ì¶”ì´",
  "data": {
    "labels": ["7ì›”", "8ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”"],
    "datasets": [{
      "label": "ì¬ê³ ëŸ‰",
      "data": [950, 920, 880, 900, 920, 850]
    }]
  }
}
```

ì¶œì²˜:
1. ë¶€í’ˆ ì¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ (MongoDB)
2. ë¶€í’ˆ ë§¤ë‰´ì–¼ v2.0 (PDF, 5í˜ì´ì§€)
3. ì¶œê³  ì´ë ¥ ë°ì´í„°ë² ì´ìŠ¤
"""
        return MockChatResponse(content=response)

    def _generate_table_response(self, prompt: str) -> MockChatResponse:
        """í‘œ/ê·¸ë˜í”„ í¬í•¨ ì‘ë‹µ ìƒì„±"""

        # ì¶œê³  ì´ë ¥ ê´€ë ¨ ì§ˆë¬¸ (ë…„ë„ë³„ ë°ì´í„°)
        if "ì¶œê³ " in prompt and ("ë…„" in prompt or "ì—°ë„" in prompt or "2021" in prompt or "2022" in prompt):
            return self._generate_yearly_shipment_response(prompt)

        # ê¸°ë³¸ ì¬ê³  í˜„í™© í‘œ
        response = """
ë¶€í’ˆë³„ ì¬ê³  í˜„í™©ì„ í‘œë¡œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤:

| ë¶€í’ˆë²ˆí˜¸ | ë¶€í’ˆëª… | ì´ ì¬ê³  | ê°€ìš© ì¬ê³  | ì˜ˆì•½ | ìƒíƒœ |
|---------|--------|---------|-----------|------|------|
| ABC-12345 | ë°˜ë„ì²´ ì¹© A | 1,000 | 850 | 150 | ì •ìƒ |
| ABC-12346 | ë°˜ë„ì²´ ì¹© B | 500 | 450 | 50 | ì •ìƒ |
| ABC-12347 | ë°˜ë„ì²´ ì¹© C | 200 | 50 | 150 | ë¶€ì¡± |

**ê·¸ë˜í”„ ë°ì´í„°**
```json
{
  "type": "bar",
  "title": "ë¶€í’ˆë³„ ì¬ê³  í˜„í™©",
  "data": {
    "labels": ["ì¹© A", "ì¹© B", "ì¹© C"],
    "datasets": [{
      "label": "ê°€ìš© ì¬ê³ ",
      "data": [850, 450, 50],
      "backgroundColor": "rgba(54, 162, 235, 0.8)"
    }, {
      "label": "ì˜ˆì•½",
      "data": [150, 50, 150],
      "backgroundColor": "rgba(255, 206, 86, 0.8)"
    }]
  }
}
```

ì¶œì²˜: ë¶€í’ˆ ì¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ
"""
        return MockChatResponse(content=response)

    def _generate_yearly_shipment_response(self, prompt: str) -> MockChatResponse:
        """ë…„ë„ë³„ ì¶œê³  ë°ì´í„° í‘œ ë° ê·¸ë˜í”„ ìƒì„±"""
        response = """
ë¶€í’ˆ ABC-12345ì˜ ìµœê·¼ 3ë…„ê°„(2021-2023) ì¶œê³  ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

## ğŸ“Š ì—°ë„ë³„ ì¶œê³  í˜„í™© ìš”ì•½

### ì´ ì¶œê³ ëŸ‰
- **2021ë…„**: 12,450ê°œ
- **2022ë…„**: 15,800ê°œ (ì „ë…„ ëŒ€ë¹„ +26.9%)
- **2023ë…„**: 18,200ê°œ (ì „ë…„ ëŒ€ë¹„ +15.2%)

---

## ğŸ“… ì›”ë³„ ì¶œê³  ì´ë ¥ (2021-2023)

| ì›” | 2021ë…„ | 2022ë…„ | 2023ë…„ | í‰ê·  |
|----|--------|--------|--------|------|
| 1ì›” | 950ê°œ | 1,200ê°œ | 1,450ê°œ | 1,200ê°œ |
| 2ì›” | 880ê°œ | 1,150ê°œ | 1,380ê°œ | 1,137ê°œ |
| 3ì›” | 1,020ê°œ | 1,280ê°œ | 1,520ê°œ | 1,273ê°œ |
| 4ì›” | 1,050ê°œ | 1,320ê°œ | 1,550ê°œ | 1,307ê°œ |
| 5ì›” | 1,100ê°œ | 1,400ê°œ | 1,620ê°œ | 1,373ê°œ |
| 6ì›” | 1,080ê°œ | 1,380ê°œ | 1,580ê°œ | 1,347ê°œ |
| 7ì›” | 990ê°œ | 1,250ê°œ | 1,480ê°œ | 1,240ê°œ |
| 8ì›” | 920ê°œ | 1,180ê°œ | 1,420ê°œ | 1,173ê°œ |
| 9ì›” | 1,040ê°œ | 1,340ê°œ | 1,590ê°œ | 1,323ê°œ |
| 10ì›” | 1,100ê°œ | 1,420ê°œ | 1,650ê°œ | 1,390ê°œ |
| 11ì›” | 1,150ê°œ | 1,480ê°œ | 1,710ê°œ | 1,447ê°œ |
| 12ì›” | 1,170ê°œ | 1,400ê°œ | 1,750ê°œ | 1,440ê°œ |
| **í•©ê³„** | **12,450ê°œ** | **15,800ê°œ** | **18,200ê°œ** | **15,483ê°œ** |

---

## ğŸ­ ë¼ì¸ë³„ ì¶œê³  ë¹„ìœ¨ (2023ë…„ ê¸°ì¤€)

| ë¼ì¸ | ì¶œê³ ëŸ‰ | ë¹„ìœ¨ | ì£¼ìš” ìš©ë„ |
|------|--------|------|-----------|
| ë¼ì¸ 1 | 7,280ê°œ | 40% | ì£¼ë ¥ ìƒì‚° ë¼ì¸ |
| ë¼ì¸ 2 | 5,460ê°œ | 30% | ë³´ì¡° ìƒì‚° ë¼ì¸ |
| ë¼ì¸ 3 | 3,640ê°œ | 20% | í…ŒìŠ¤íŠ¸/ê²€ì¦ |
| ê¸°íƒ€ | 1,820ê°œ | 10% | ìœ ì§€ë³´ìˆ˜/ì˜ˆë¹„ |
| **í•©ê³„** | **18,200ê°œ** | **100%** | - |

---

## ğŸ“ˆ 3ë…„ê°„ ì¶œê³  ì¶”ì´ ê·¸ë˜í”„

```json
{
  "type": "line",
  "title": "ì›”ë³„ ì¶œê³  ì¶”ì´ (2021-2023)",
  "data": {
    "labels": ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”"],
    "datasets": [
      {
        "label": "2021ë…„",
        "data": [950, 880, 1020, 1050, 1100, 1080, 990, 920, 1040, 1100, 1150, 1170],
        "borderColor": "rgba(75, 192, 192, 1)",
        "backgroundColor": "rgba(75, 192, 192, 0.2)",
        "tension": 0.4
      },
      {
        "label": "2022ë…„",
        "data": [1200, 1150, 1280, 1320, 1400, 1380, 1250, 1180, 1340, 1420, 1480, 1400],
        "borderColor": "rgba(54, 162, 235, 1)",
        "backgroundColor": "rgba(54, 162, 235, 0.2)",
        "tension": 0.4
      },
      {
        "label": "2023ë…„",
        "data": [1450, 1380, 1520, 1550, 1620, 1580, 1480, 1420, 1590, 1650, 1710, 1750],
        "borderColor": "rgba(255, 99, 132, 1)",
        "backgroundColor": "rgba(255, 99, 132, 0.2)",
        "tension": 0.4
      }
    ]
  }
}
```

---

## ğŸ“Š ì—°ë„ë³„ ì´ ì¶œê³ ëŸ‰ ë¹„êµ (ë§‰ëŒ€ ê·¸ë˜í”„)

```json
{
  "type": "bar",
  "title": "ì—°ë„ë³„ ì´ ì¶œê³ ëŸ‰",
  "data": {
    "labels": ["2021ë…„", "2022ë…„", "2023ë…„"],
    "datasets": [{
      "label": "ì¶œê³ ëŸ‰ (ê°œ)",
      "data": [12450, 15800, 18200],
      "backgroundColor": [
        "rgba(75, 192, 192, 0.8)",
        "rgba(54, 162, 235, 0.8)",
        "rgba(255, 99, 132, 0.8)"
      ],
      "borderColor": [
        "rgba(75, 192, 192, 1)",
        "rgba(54, 162, 235, 1)",
        "rgba(255, 99, 132, 1)"
      ],
      "borderWidth": 2
    }]
  }
}
```

---

## ğŸ¯ ë¼ì¸ë³„ ì¶œê³  ë¹„ìœ¨ (íŒŒì´ ì°¨íŠ¸)

```json
{
  "type": "pie",
  "title": "ë¼ì¸ë³„ ì¶œê³  ë¹„ìœ¨ (2023ë…„)",
  "data": {
    "labels": ["ë¼ì¸ 1 (40%)", "ë¼ì¸ 2 (30%)", "ë¼ì¸ 3 (20%)", "ê¸°íƒ€ (10%)"],
    "datasets": [{
      "data": [7280, 5460, 3640, 1820],
      "backgroundColor": [
        "rgba(255, 99, 132, 0.8)",
        "rgba(54, 162, 235, 0.8)",
        "rgba(255, 206, 86, 0.8)",
        "rgba(75, 192, 192, 0.8)"
      ],
      "borderColor": [
        "rgba(255, 99, 132, 1)",
        "rgba(54, 162, 235, 1)",
        "rgba(255, 206, 86, 1)",
        "rgba(75, 192, 192, 1)"
      ],
      "borderWidth": 2
    }]
  }
}
```

---

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

1. **ì§€ì†ì ì¸ ì„±ì¥ì„¸**: 2021ë…„ ëŒ€ë¹„ 2023ë…„ 46.2% ì¦ê°€
2. **ì„±ìˆ˜ê¸°**: 10-12ì›” ì¶œê³ ëŸ‰ì´ ê°€ì¥ ë§ìŒ (í‰ê·  ëŒ€ë¹„ +15%)
3. **ë¹„ìˆ˜ê¸°**: 2ì›”, 8ì›” ì¶œê³ ëŸ‰ ê°ì†Œ ê²½í–¥ (ì„¤ ì—°íœ´, íœ´ê°€ ì‹œì¦Œ)
4. **ë¼ì¸ 1 ì§‘ì¤‘ë„**: ì „ì²´ ì¶œê³ ì˜ 40%ê°€ ë¼ì¸ 1ì— ì§‘ì¤‘
5. **ì•ˆì •ì  ìˆ˜ìš”**: ë§¤ë…„ í‰ê·  12-15% ì„±ì¥ë¥  ìœ ì§€

---

**ì¶œì²˜:**
1. ë¶€í’ˆ ì¶œê³  ê´€ë¦¬ ì‹œìŠ¤í…œ (MongoDB)
2. ìƒì‚° ë¼ì¸ ìš´ì˜ ë°ì´í„°ë² ì´ìŠ¤
3. 2021-2023 ì—°ê°„ ìƒì‚° ë³´ê³ ì„œ (PDF)
"""
        return MockChatResponse(content=response)


class MockEmbeddingLLM:
    """Mock Embedding LLM - ì‚¬ë‚´ Embedding LLM ëŒ€ì²´"""

    def __init__(self, model: str = "mock-embedding"):
        self.model = model
        self.dimension = 1536  # OpenAI embedding ì°¨ì›

    def embed_query(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (Mock)"""
        time.sleep(0.2)
        # ì‹¤ì œë¡œëŠ” ëœë¤ì´ì§€ë§Œ ê°™ì€ í…ìŠ¤íŠ¸ëŠ” ê°™ì€ ë²¡í„° ë°˜í™˜
        random.seed(hash(text) % (2**32))
        return [random.random() for _ in range(self.dimension)]

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        return [self.embed_query(text) for text in texts]


class MockVisionLLM:
    """Mock Vision LLM - ì‚¬ë‚´ Vision LLM ëŒ€ì²´"""

    def __init__(self, model: str = "mock-gpt-4-vision"):
        self.model = model

    def analyze_image(self, image_path: str, prompt: str = "") -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ë¶„ì„ (Mock)"""
        time.sleep(1.0)

        # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ì‘ë‹µ
        if "table" in image_path.lower() or "í‘œ" in image_path:
            return {
                "type": "table",
                "description": "ë¶€í’ˆ ì‚¬ì–‘ ë¹„êµí‘œ",
                "extracted_data": {
                    "headers": ["ë¶€í’ˆë²ˆí˜¸", "ì „ì••", "ì „ë¥˜", "ì˜¨ë„ë²”ìœ„"],
                    "rows": [
                        ["ABC-12345", "3.3V", "0.5A", "-40~85Â°C"],
                        ["ABC-12346", "5.0V", "0.8A", "-20~70Â°C"]
                    ]
                }
            }

        if "graph" in image_path.lower() or "chart" in image_path.lower():
            return {
                "type": "graph",
                "description": "ì›”ë³„ ë¶€í’ˆ ì†Œë¹„ëŸ‰ ì¶”ì´ ê·¸ë˜í”„",
                "chart_type": "line",
                "data": {
                    "x_axis": ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”"],
                    "y_axis": [120, 150, 130, 180, 200],
                    "unit": "ê°œ"
                }
            }

        return {
            "type": "image",
            "description": "ë°˜ë„ì²´ ë¶€í’ˆ ë‹¤ì´ì–´ê·¸ë¨",
            "details": "ë¶€í’ˆì˜ ë‚´ë¶€ êµ¬ì¡°ì™€ í•€ ë°°ì¹˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ë‹¤ì´ì–´ê·¸ë¨"
        }


class MockLLMFactory:
    """Mock LLM íŒ©í† ë¦¬ - í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì‚¬ìš©"""

    @staticmethod
    def create_chat_llm(config: Any) -> MockChatLLM:
        """Chat LLM ìƒì„±"""
        return MockChatLLM(
            model=config.llm.chat_model,
            temperature=config.llm.temperature
        )

    @staticmethod
    def create_embedding_llm(config: Any) -> MockEmbeddingLLM:
        """Embedding LLM ìƒì„±"""
        return MockEmbeddingLLM(model=config.llm.embedding_model)

    @staticmethod
    def create_vision_llm(config: Any) -> MockVisionLLM:
        """Vision LLM ìƒì„±"""
        return MockVisionLLM(model=config.llm.vision_model)
