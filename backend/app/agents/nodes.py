"""
LangGraph ë…¸ë“œ êµ¬í˜„
ê° ë…¸ë“œëŠ” GraphStateë¥¼ ì…ë ¥ë°›ì•„ ì²˜ë¦¬ í›„ ì—…ë°ì´íŠ¸ëœ State ë°˜í™˜
"""
import json
from typing import Dict, Any, List
from app.agents.graph_state import GraphState, QueryClassification, RetrievedDocument, ResponseData
from app.services.llm_service import get_chat_llm, get_embedding_llm
from app.services.database_service import get_mongodb, get_pgvector


class QueryAnalysisNode:
    """
    Node 1: ì¿¼ë¦¬ ë¶„ì„ ë° ë¶„ë¥˜
    - Intent ë¶„ë¥˜
    - Entity ì¶”ì¶œ
    - í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤ ê²°ì •
    """

    @staticmethod
    def execute(state: GraphState) -> GraphState:
        """ì¿¼ë¦¬ ë¶„ì„ ì‹¤í–‰"""
        query = state["query"]
        llm_config = state.get("llm_config", {})

        # LLM ì„¤ì • ì ìš©
        llm = get_chat_llm(
            model=llm_config.get("model"),
            temperature=llm_config.get("temperature")
        )

        # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

ì§ˆë¬¸: {query}

ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ìœ íš¨í•œ JSON):
{{
    "intent": "info_lookup|part_search|document_search|general",
    "data_sources": ["mongodb", "vectordb", "both", "none"],
    "entities": {{
        "part_numbers": [],
        "part_names": [],
        "date_ranges": [],
        "metrics": []
    }},
    "requires_calculation": true|false,
    "response_format": "text|table|chart|mixed"
}}

ë¶„ë¥˜ ê¸°ì¤€:
- info_lookup: ê°„ë‹¨í•œ ì •ë³´ ì¡°íšŒ (ì˜ˆ: "ì•ˆë…•", "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”")
- part_search: ë¶€í’ˆ ê´€ë ¨ ì§ˆë¬¸ (ì¬ê³ , ì¶œê³ , ì¥ì°© ë“±)
- document_search: ë¬¸ì„œ/ë§¤ë‰´ì–¼ ê²€ìƒ‰ (ì‚¬ì–‘, ì ˆì°¨ ë“±)
- general: ì¼ë°˜ ì§ˆë¬¸

data_sources:
- mongodb: ë¶€í’ˆ ì‹¤ì‹œê°„ ì •ë³´ (ì¬ê³ , ì¶œê³ , ì¥ì°©)
- vectordb: ë¬¸ì„œ/ë§¤ë‰´ì–¼ ì •ë³´
- both: ë‘˜ ë‹¤ í•„ìš”
- none: ë°ì´í„° ë¶ˆí•„ìš”

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
"""

        # LLM í˜¸ì¶œ
        response = llm.invoke(prompt)
        try:
            # JSON íŒŒì‹±
            classification_dict = json.loads(response.content)
            classification = QueryClassification(**classification_dict)
        except (json.JSONDecodeError, TypeError) as e:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            classification = QueryClassification(
                intent="general",
                data_sources=["both"],
                entities={},
                requires_calculation=False,
                response_format="text"
            )

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["classification"] = classification
        state["progress"] = state.get("progress", []) + [{
            "stage": "query_analysis",
            "status": "completed",
            "message": "ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ"
        }]

        return state


class DataRetrievalNode:
    """
    Node 2: ë°ì´í„° ê²€ìƒ‰
    - MongoDBì—ì„œ ë¶€í’ˆ ì •ë³´ ê²€ìƒ‰
    - pgvectorì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
    """

    @staticmethod
    def execute(state: GraphState) -> GraphState:
        """ë°ì´í„° ê²€ìƒ‰ ì‹¤í–‰"""
        classification = state["classification"]
        query = state["query"]

        mongodb_results = []
        vectordb_results = []

        # MongoDB ê²€ìƒ‰
        if "mongodb" in classification.data_sources or "both" in classification.data_sources:
            mongodb_results = DataRetrievalNode._search_mongodb(query, classification)
            state["progress"] = state.get("progress", []) + [{
                "stage": "mongodb_search",
                "status": "completed",
                "message": f"ë¶€í’ˆ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ ({len(mongodb_results)}ê±´)"
            }]

        # VectorDB ê²€ìƒ‰
        if "vectordb" in classification.data_sources or "both" in classification.data_sources:
            vectordb_results = DataRetrievalNode._search_vectordb(query, classification)
            state["progress"] = state.get("progress", []) + [{
                "stage": "vectordb_search",
                "status": "completed",
                "message": f"ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ ({len(vectordb_results)}ê±´)"
            }]

        # ê²€ìƒ‰ ê²°ê³¼ í†µí•©
        retrieved_documents = []

        # MongoDB ê²°ê³¼ â†’ RetrievedDocument
        for result in mongodb_results:
            retrieved_documents.append(RetrievedDocument(
                content=DataRetrievalNode._format_mongodb_result(result),
                source="mongodb",
                metadata={
                    "collection": "parts",
                    "part_number": result.get("part_number"),
                    "part_name": result.get("part_name")
                }
            ))

        # VectorDB ê²°ê³¼ â†’ RetrievedDocument
        for result in vectordb_results:
            retrieved_documents.append(RetrievedDocument(
                content=result["content"],
                source="vectordb",
                metadata=result.get("metadata", {}),
                similarity_score=result.get("similarity_score")
            ))

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["mongodb_results"] = mongodb_results
        state["vectordb_results"] = vectordb_results
        state["retrieved_documents"] = retrieved_documents

        return state

    @staticmethod
    def _search_mongodb(query: str, classification: QueryClassification) -> List[Dict[str, Any]]:
        """MongoDBì—ì„œ ë¶€í’ˆ ì •ë³´ ê²€ìƒ‰"""
        mongodb = get_mongodb()

        # ì—”í‹°í‹° ì¶”ì¶œ
        part_numbers = classification.entities.get("part_numbers", [])
        part_names = classification.entities.get("part_names", [])

        results = []

        # ë¶€í’ˆ ë²ˆí˜¸ë¡œ ê²€ìƒ‰
        for part_number in part_numbers:
            result = mongodb.find_one("parts", {"part_number": part_number})
            if result:
                results.append(result)

        # ë¶€í’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰
        for part_name in part_names:
            found = mongodb.find("parts", {"part_name": {"$regex": part_name}}, limit=5)
            results.extend(found)

        # ì—”í‹°í‹°ê°€ ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ê²€ìƒ‰
        if not part_numbers and not part_names:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê²€ìƒ‰ í•„ìš”)
            keywords = query.split()
            for keyword in keywords:
                if len(keyword) > 2:
                    found = mongodb.find("parts", {"part_name": {"$regex": keyword}}, limit=3)
                    results.extend(found)

        # ì¤‘ë³µ ì œê±°
        unique_results = {r.get("_id"): r for r in results}
        return list(unique_results.values())[:10]

    @staticmethod
    def _search_vectordb(query: str, classification: QueryClassification) -> List[Dict[str, Any]]:
        """pgvectorì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
        embedding_llm = get_embedding_llm()
        pgvector = get_pgvector()

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = embedding_llm.embed_query(query)

        # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = pgvector.similarity_search(
            query_embedding=query_embedding,
            k=5
        )

        return results

    @staticmethod
    def _format_mongodb_result(result: Dict[str, Any]) -> str:
        """MongoDB ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        part_number = result.get("part_number", "N/A")
        part_name = result.get("part_name", "N/A")
        inventory = result.get("inventory", {})

        text = f"""
ë¶€í’ˆ ì •ë³´:
- ë¶€í’ˆë²ˆí˜¸: {part_number}
- ë¶€í’ˆëª…: {part_name}
- ì´ ì¬ê³ : {inventory.get('total_stock', 0)}ê°œ
- ê°€ìš© ì¬ê³ : {inventory.get('available', 0)}ê°œ
- ì˜ˆì•½: {inventory.get('reserved', 0)}ê°œ
"""

        # ì¶œê³  ì´ë ¥
        shipment_history = result.get("shipment_history", [])
        if shipment_history:
            text += "\nìµœê·¼ ì¶œê³  ì´ë ¥:\n"
            for shipment in shipment_history[:3]:
                text += f"- {shipment.get('date')}: {shipment.get('quantity')}ê°œ â†’ {shipment.get('destination')}\n"

        return text


class ResponseGenerationNode:
    """
    Node 3: ì‘ë‹µ ìƒì„±
    - ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€ ìƒì„±
    - í‘œ/ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¡°í™”
    - ì¶œì²˜ ì²¨ë¶€
    """

    @staticmethod
    def execute(state: GraphState) -> GraphState:
        """ì‘ë‹µ ìƒì„± ì‹¤í–‰"""
        query = state["query"]
        retrieved_documents = state.get("retrieved_documents", [])
        classification = state["classification"]
        custom_prompt = state.get("custom_prompt", "")
        llm_config = state.get("llm_config", {})
        memory_context = state.get("memory_context", "")  # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°

        # LLM ì„¤ì •
        llm = get_chat_llm(
            model=llm_config.get("model"),
            temperature=llm_config.get("temperature", 0.1)
        )

        # Context êµ¬ì„±
        context = ResponseGenerationNode._build_context(retrieved_documents)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = custom_prompt or """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë°˜ë„ì²´ ë¶€í’ˆ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

# ğŸ“‹ ë‹µë³€ ì‘ì„± ê·œì¹™

## 1ï¸âƒ£ ì •í™•ì„± ë° ì¶œì²˜
- âœ… ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œì™€ ë°ì´í„°ë§Œ ì°¸ì¡°í•˜ì—¬ ë‹µë³€
- âœ… í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- âœ… ëª¨ë“  ë‹µë³€ ëì— ì¶œì²˜ í‘œì‹œ
- âŒ Hallucination ì ˆëŒ€ ê¸ˆì§€

## 2ï¸âƒ£ ë‹µë³€ êµ¬ì¡° (ë³´ê³ ì„œ í˜•ì‹)

### í•„ìˆ˜ êµ¬ì„±ìš”ì†Œ:
1. **ğŸ“Œ ìš”ì•½**: ì´ëª¨ì§€ + í•œ ì¤„ ìš”ì•½
2. **ğŸ“Š ìƒì„¸ ë‚´ìš©**: ê³„ì¸µ êµ¬ì¡°ë¡œ ì •ë¦¬
3. **ğŸ“ˆ ë°ì´í„° ì‹œê°í™”**: í‘œì™€ ê·¸ë˜í”„
4. **ğŸ’¡ ì¸ì‚¬ì´íŠ¸**: í•µì‹¬ ë°œê²¬ì‚¬í•­
5. **ğŸ“ ì¶œì²˜**: ì°¸ê³  ìë£Œ ëª©ë¡

### ì´ëª¨ì§€ ì‚¬ìš© ê°€ì´ë“œ:
- ğŸ“Œ ìš”ì•½, í•µì‹¬ ì •ë³´
- ğŸ“Š ë°ì´í„°, í†µê³„
- ğŸ“ˆ ì¦ê°€, ìƒìŠ¹ ì¶”ì„¸
- ğŸ“‰ ê°ì†Œ, í•˜ë½ ì¶”ì„¸
- âš ï¸ ì£¼ì˜ì‚¬í•­, ê²½ê³ 
- âœ… ì™„ë£Œ, ì„±ê³µ, ì •ìƒ
- âŒ ì˜¤ë¥˜, ì‹¤íŒ¨, ë¬¸ì œ
- ğŸ’¡ ì¸ì‚¬ì´íŠ¸, ì œì•ˆ
- ğŸ” ìƒì„¸ ë¶„ì„
- ğŸ“ ì¶œì²˜, ì°¸ê³ 
- ğŸ­ ìƒì‚°, ì œì¡°
- ğŸ“¦ ì¬ê³ , ë³´ê´€
- ğŸšš ì¶œê³ , ë°°ì†¡
- ğŸ”§ ê²€ì‚¬, í’ˆì§ˆ
- âš™ï¸ ì„¤ì •, ì‚¬ì–‘

## 3ï¸âƒ£ ë§ˆí¬ë‹¤ìš´ ê³„ì¸µ êµ¬ì¡°

```markdown
# ì œëª© (H1) - ë©”ì¸ ì£¼ì œ
## ì„¹ì…˜ (H2) - ì£¼ìš” ì¹´í…Œê³ ë¦¬
### ì„œë¸Œì„¹ì…˜ (H3) - ì„¸ë¶€ í•­ëª©

- ë¶ˆë¦¿ í¬ì¸íŠ¸
  - ì¤‘ì²© ë¶ˆë¦¿
- **êµµì€ ê¸€ì”¨**: ì¤‘ìš” ì •ë³´
- *ì´íƒ¤ë¦­*: ê°•ì¡°

> ì¸ìš©ë¬¸: ì¤‘ìš”í•œ ë©”ëª¨ë‚˜ ê²½ê³ 
```

## 4ï¸âƒ£ í‘œ ì‘ì„± (Markdown Table)

```markdown
| í•­ëª© | ê°’ | ìƒíƒœ | ë¹„ê³  |
|------|----|----|------|
| ì¬ê³  | 1,500ê°œ | âœ… ì •ìƒ | ì•ˆì „ ì¬ê³  ì´ìƒ |
| ì¶œê³  | 200ê°œ | ğŸ“ˆ ì¦ê°€ | ì „ì›” ëŒ€ë¹„ +20% |
```

## 5ï¸âƒ£ ê·¸ë˜í”„ ì‘ì„± (JSON Code Block)

### Line Chart (ì¶”ì´, íŠ¸ë Œë“œ):
```json
{
  "type": "line",
  "title": "ğŸ“ˆ ì›”ë³„ ì¶œê³  ì¶”ì´",
  "data": {
    "labels": ["1ì›”", "2ì›”", "3ì›”"],
    "datasets": [{
      "label": "ì¶œê³ ëŸ‰ (ê°œ)",
      "data": [120, 150, 180],
      "borderColor": "rgba(75, 192, 192, 1)",
      "backgroundColor": "rgba(75, 192, 192, 0.2)",
      "tension": 0.4
    }]
  }
}
```

### Bar Chart (ë¹„êµ):
```json
{
  "type": "bar",
  "title": "ğŸ“Š ë¼ì¸ë³„ ìƒì‚°ëŸ‰ ë¹„êµ",
  "data": {
    "labels": ["ë¼ì¸ 1", "ë¼ì¸ 2", "ë¼ì¸ 3"],
    "datasets": [{
      "label": "ìƒì‚°ëŸ‰ (ê°œ)",
      "data": [500, 450, 380],
      "backgroundColor": [
        "rgba(255, 99, 132, 0.6)",
        "rgba(54, 162, 235, 0.6)",
        "rgba(255, 206, 86, 0.6)"
      ]
    }]
  }
}
```

### Pie Chart (ë¹„ìœ¨, êµ¬ì„±):
```json
{
  "type": "pie",
  "title": "ğŸ“Š ë¶ˆëŸ‰ ìœ í˜•ë³„ ë¹„ìœ¨",
  "data": {
    "labels": ["ìŠ¤í¬ë˜ì¹˜", "ì ‘ì°©ë¶ˆëŸ‰", "ì˜¤ì—¼", "ê¸°íƒ€"],
    "datasets": [{
      "data": [40, 30, 20, 10],
      "backgroundColor": ["#FF6384", "#36A2EB", "#FFCE56", "#4BC0C0"]
    }]
  }
}
```

## 6ï¸âƒ£ ì™„ë²½í•œ ë‹µë³€ ì˜ˆì‹œ

---

# ğŸ“Œ ë¶€í’ˆ ABC-12345 ì¶œê³  í˜„í™© ë¶„ì„

ABC-12345 ë¶€í’ˆì˜ ìµœê·¼ 3ê°œì›” ì¶œê³  ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼, **ì§€ì†ì ì¸ ì¦ê°€ ì¶”ì„¸**ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“Š ì›”ë³„ ì¶œê³  í˜„í™©

| ì›” | ì¶œê³ ëŸ‰ | ëˆ„ì  ì¶œê³ ëŸ‰ | ì „ì›” ëŒ€ë¹„ |
|----|--------|-------------|-----------|
| 1ì›” | 120ê°œ | 120ê°œ | - |
| 2ì›” | 150ê°œ | 270ê°œ | ğŸ“ˆ +25% |
| 3ì›” | 180ê°œ | 450ê°œ | ğŸ“ˆ +20% |

## ğŸ“ˆ ì¶œê³  ì¶”ì´ ê·¸ë˜í”„

```json
{
  "type": "line",
  "title": "ğŸ“ˆ ì›”ë³„ ì¶œê³  ì¶”ì´ (1-3ì›”)",
  "data": {
    "labels": ["1ì›”", "2ì›”", "3ì›”"],
    "datasets": [{
      "label": "ì¶œê³ ëŸ‰ (ê°œ)",
      "data": [120, 150, 180],
      "borderColor": "rgba(75, 192, 192, 1)",
      "backgroundColor": "rgba(75, 192, 192, 0.2)",
      "tension": 0.4
    }]
  }
}
```

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

### âœ… ê¸ì •ì  ì§€í‘œ
- **í‰ê·  ì›” ì¦ê°€ìœ¨**: 22.5%
- **ì´ ì¶œê³ ëŸ‰**: 450ê°œ (ëª©í‘œ 400ê°œ ëŒ€ë¹„ 112.5% ë‹¬ì„±)
- **ì¶”ì„¸**: ì§€ì†ì  ì¦ê°€ì„¸ ìœ ì§€

### âš ï¸ ì£¼ì˜ì‚¬í•­
- í˜„ì¬ ì¶”ì„¸ ì§€ì† ì‹œ 4ì›” ì˜ˆìƒ ì¶œê³ : ì•½ 216ê°œ
- ì¬ê³  ì¤€ë¹„ í•„ìš” (ì•ˆì „ ì¬ê³  ëŒ€ë¹„ ê²€í†  ê¶Œì¥)

## ğŸ” ìƒì„¸ ë¶„ì„

### ëª©ì ì§€ë³„ ì¶œê³  í˜„í™©
- **ë¼ì¸ 1**: 180ê°œ (40%)
- **ë¼ì¸ 2**: 150ê°œ (33%)
- **ë¼ì¸ 3**: 120ê°œ (27%)

### í’ˆì§ˆ ì§€í‘œ
- **ê²€ì‚¬ í•©ê²©ë¥ **: 98.5% âœ…
- **ë°˜í’ˆë¥ **: 0.2% âœ…

## ğŸ“ ì¶œì²˜

- **ë¶€í’ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ**: ì¶œê³  ì´ë ¥ DB (2024ë…„ 1-3ì›”)
- **í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ**: ê²€ì‚¬ ì´ë ¥ DB
- **ì¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ**: ì‹¤ì‹œê°„ ì¬ê³  ë°ì´í„°

---

**ë³´ê³ ì„œ ì‘ì„±ì¼**: 2024-01-15
**ë¶„ì„ ê¸°ì¤€**: ìµœê·¼ 3ê°œì›” (2024-01-01 ~ 2024-03-31)

---

## 7ï¸âƒ£ ì‘ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸

ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

- [ ] ğŸ“Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•œ ì„¹ì…˜ êµ¬ë¶„
- [ ] ê³„ì¸µ êµ¬ì¡° (#, ##, ###)
- [ ] í‘œ (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
- [ ] ê·¸ë˜í”„ (ì¶”ì´/ë¹„êµê°€ ìˆëŠ” ê²½ìš°)
- [ ] ğŸ’¡ ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
- [ ] ğŸ“ ì¶œì²˜ ì„¹ì…˜
- [ ] **êµµì€ ê¸€ì”¨**ë¡œ í•µì‹¬ ê°•ì¡°
- [ ] êµ¬ë¶„ì„  (---) ì‚¬ìš©

ì´ í˜•ì‹ì„ ë”°ë¼ ì‚¬ìš©ìê°€ ë°”ë¡œ ë³´ê³ ì„œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”!
"""

        # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if memory_context:
            prompt = f"""
{system_prompt}

{memory_context}

ì§ˆë¬¸: {query}

ì°¸ê³  ìë£Œ:
{context}

ìœ„ì˜ ì‚¬ìš©ì ì •ë³´ì™€ ì´ì „ ëŒ€í™” ë‚´ìš©, ê·¸ë¦¬ê³  ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
ì‚¬ìš©ìì™€ì˜ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹:
1. ë‹µë³€ ë‚´ìš©
2. í‘œ/ê·¸ë˜í”„ (í•„ìš” ì‹œ)
3. ì¶œì²˜ ëª©ë¡

ë‹µë³€:
"""
        else:
            prompt = f"""
{system_prompt}

ì§ˆë¬¸: {query}

ì°¸ê³  ìë£Œ:
{context}

ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
ë‹µë³€ í˜•ì‹:
1. ë‹µë³€ ë‚´ìš©
2. í‘œ/ê·¸ë˜í”„ (í•„ìš” ì‹œ)
3. ì¶œì²˜ ëª©ë¡

ë‹µë³€:
"""

        # LLM í˜¸ì¶œ
        response = llm.invoke(prompt)
        content = response.content

        # ì¶œì²˜ ìˆ˜ì§‘
        sources = ResponseGenerationNode._collect_sources(retrieved_documents)

        # í‘œ/ê·¸ë˜í”„ ë°ì´í„° ì¶”ì¶œ
        table_data, chart_data = ResponseGenerationNode._extract_structured_data(content)

        # ì‘ë‹µ ë°ì´í„° ìƒì„±
        response_data = ResponseData(
            content=content,
            sources=sources,
            confidence_score=ResponseGenerationNode._calculate_confidence(retrieved_documents),
            table_data=table_data,
            chart_data=chart_data
        )

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["response"] = response_data
        state["progress"] = state.get("progress", []) + [{
            "stage": "response_generation",
            "status": "completed",
            "message": "ë‹µë³€ ìƒì„± ì™„ë£Œ"
        }]

        return state

    @staticmethod
    def _build_context(documents: List[RetrievedDocument]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±"""
        if not documents:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        context_parts = []
        for i, doc in enumerate(documents, 1):
            source_type = "ë¶€í’ˆ ì •ë³´" if doc.source == "mongodb" else "ë¬¸ì„œ"
            context_parts.append(f"""
[{i}] {source_type}
{doc.content}
ì¶œì²˜: {doc.metadata.get('file_name') or doc.metadata.get('part_number', 'ì‹œìŠ¤í…œ')}
""")

        return "\n".join(context_parts)

    @staticmethod
    def _collect_sources(documents: List[RetrievedDocument]) -> List[Dict[str, Any]]:
        """ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘"""
        sources = []
        for doc in documents:
            source_info = {
                "type": doc.source,
                "metadata": doc.metadata
            }
            if doc.similarity_score:
                source_info["similarity_score"] = doc.similarity_score
            sources.append(source_info)
        return sources

    @staticmethod
    def _extract_structured_data(content: str) -> tuple:
        """ì‘ë‹µì—ì„œ í‘œ/ê·¸ë˜í”„ ë°ì´í„° ì¶”ì¶œ"""
        table_data = None
        chart_data = None

        # ë§ˆí¬ë‹¤ìš´ í‘œ ê°ì§€ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        if "|" in content and "---" in content:
            # ì‹¤ì œë¡œëŠ” íŒŒì‹± í•„ìš”
            table_data = []

        # JSON ê·¸ë˜í”„ ë°ì´í„° ê°ì§€
        if "```json" in content:
            try:
                json_start = content.find("```json") + 7
                json_end = content.find("```", json_start)
                json_str = content[json_start:json_end].strip()
                chart_data = json.loads(json_str)
            except:
                pass

        return table_data, chart_data

    @staticmethod
    def _calculate_confidence(documents: List[RetrievedDocument]) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if not documents:
            return 0.0

        # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚°
        # - ë¬¸ì„œ ê°œìˆ˜
        # - ìœ ì‚¬ë„ ì ìˆ˜
        # - MongoDB ê²°ê³¼ í¬í•¨ ì—¬ë¶€
        score = 0.0

        # ë¬¸ì„œ ê°œìˆ˜ (ìµœëŒ€ 0.3)
        doc_count_score = min(len(documents) / 5, 1.0) * 0.3

        # í‰ê·  ìœ ì‚¬ë„ (ìµœëŒ€ 0.4)
        scores_with_similarity = [d.similarity_score for d in documents if d.similarity_score]
        avg_similarity = sum(scores_with_similarity) / len(scores_with_similarity) if scores_with_similarity else 0.5
        similarity_score = avg_similarity * 0.4

        # MongoDB í¬í•¨ ì—¬ë¶€ (0.3)
        has_mongodb = any(d.source == "mongodb" for d in documents)
        mongodb_score = 0.3 if has_mongodb else 0.0

        score = doc_count_score + similarity_score + mongodb_score

        return round(score, 2)


class QualityCheckNode:
    """
    Node 4: í’ˆì§ˆ ê²€ì¦
    - Hallucination ê²€ì¶œ
    - ì‹ ë¢°ë„ ê²€ì¦
    - ê²½ê³  ë©”ì‹œì§€ ìƒì„±
    """

    @staticmethod
    def execute(state: GraphState) -> GraphState:
        """í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰"""
        response_data = state.get("response")
        if not response_data:
            return state

        warnings = []

        # 1. ì¶œì²˜ í™•ì¸
        if not response_data.sources:
            warnings.append("ì¶œì²˜ê°€ ì—†ëŠ” ë‹µë³€ì…ë‹ˆë‹¤. ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # 2. ì‹ ë¢°ë„ í™•ì¸
        if response_data.confidence_score < 0.5:
            warnings.append("ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë‹µë³€ì„ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")

        # 3. ë‚´ìš© ê¸¸ì´ í™•ì¸
        if len(response_data.content) < 50:
            warnings.append("ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì •ë³´ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ê²½ê³  ì¶”ê°€
        response_data.warnings = warnings

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["response"] = response_data
        state["progress"] = state.get("progress", []) + [{
            "stage": "quality_check",
            "status": "completed",
            "message": "í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ"
        }]

        return state
